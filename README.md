# 模型Token输出速率测试工具

这是一个用于测试AI模型Token输出速率的Python工具，支持并发测试、报告生成和结果保存等功能。

## 功能特点

- ✅ **固定并发测试**: 支持1、2、4、8、10五种并发级别
- ✅ **可配置模型**: 可手动修改模型URL和模型名称
- ✅ **随机长文本测试**: 使用预设的长文本问题模板进行测试
- ✅ **详细报告**: 生成文本报告和图表报告
- ✅ **结果保存**: 自动保存测试结果和响应内容，避免乱码问题
- ✅ **性能分析**: 提供扩展性分析和最佳并发数建议

## 安装依赖

```bash
pip install -r requirements.txt
```

## 使用方法

### 1. 基本使用

```bash
python model_token_rate_test.py
```

### 2. 配置修改

在运行前，您需要修改 `model_token_rate_test.py` 文件中的配置：

```python
# 在main()函数中修改以下配置
config.model_url = "http://your-model-server:8000/v1/chat/completions"
config.model_name = "your-model-name"
config.api_key = "your-api-key"
config.max_tokens = 2000  # 最大输出token数
config.temperature = 0.7  # 温度参数
config.timeout = 60       # 超时时间(秒)
```

### 3. 支持的模型API格式

工具支持标准的OpenAI兼容API格式：

```json
{
  "model": "model-name",
  "messages": [{"role": "user", "content": "prompt"}],
  "max_tokens": 2000,
  "temperature": 0.7,
  "stream": false
}
```

响应格式应包含：
```json
{
  "choices": [{"message": {"content": "response"}}],
  "usage": {"total_tokens": 1234}
}
```

## 输出文件

运行完成后，工具会生成以下文件：

### 1. 测试报告
- `token_rate_report_YYYYMMDD_HHMMSS.txt` - 详细文本报告
- `token_rate_chart_YYYYMMDD_HHMMSS.png` - 图表报告

### 2. 响应内容
- `responses/` 目录下的响应文件，格式为：
  - `concurrency_X_task_Y_YYYYMMDD_HHMMSS.txt`

## 报告内容

### 文本报告包含：
- 测试配置信息
- 总体统计（总请求数、成功率等）
- 详细测试结果表格
- 性能分析（最佳并发数、扩展性分析）

### 图表报告包含：
1. **Token输出速率 vs 并发数** - 显示不同并发数下的token输出速率
2. **总Token数 vs 并发数** - 显示不同并发数下的总token数
3. **平均响应时间 vs 并发数** - 显示不同并发数下的响应时间
4. **成功率 vs 并发数** - 显示不同并发数下的成功率

## 测试问题模板

工具内置了10个长文本测试问题，涵盖：
- 人工智能发展历程
- 气候变化分析
- 量子计算原理
- 区块链技术
- 机器学习概念
- 生物技术进展
- 云计算服务
- 可再生能源
- 物联网技术
- 数字经济分析

## 注意事项

1. **API限制**: 工具在并发测试间添加了2秒间隔，避免触发API限制
2. **编码处理**: 所有文件保存都使用UTF-8编码，避免乱码问题
3. **错误处理**: 完善的异常处理机制，确保测试的稳定性
4. **资源管理**: 使用异步IO和连接池，提高测试效率

## 示例输出

```
模型Token输出速率测试工具
==================================================
当前配置:
  模型URL: http://localhost:8000/v1/chat/completions
  模型名称: gpt-3.5-turbo
  最大Token数: 2000
  温度参数: 0.7

是否使用当前配置开始测试? (y/n): y

==================================================
测试完成！
==================================================
============================================================
模型Token输出速率测试报告
============================================================
测试时间: 2024-01-15 14:30:25
模型URL: http://localhost:8000/v1/chat/completions
模型名称: gpt-3.5-turbo
最大Token数: 2000
温度参数: 0.7

总体统计:
  总请求数: 25
  成功请求: 25
  失败请求: 0
  成功率: 100.00%

详细测试结果:
------------------------------------------------------------
并发数   Token/s      总Token    总时间(s)    成功率    平均响应时间(s)  
------------------------------------------------------------
1        15.23        1523       100.12      100.00%   100.12        
2        28.45        2845       100.05      100.00%   50.03         
4        52.18        5218       100.08      100.00%   25.02         
8        89.67        8967       100.03      100.00%   12.50         
10       112.34       11234      100.01      100.00%   10.00         
------------------------------------------------------------

性能分析:
  最佳并发数: 10 (Token/s: 112.34)
  扩展性分析:
    并发数2: 效率 93.4%
    并发数4: 效率 85.7%
    并发数8: 效率 73.6%
    并发数10: 效率 73.8%

============================================================
```

## 故障排除

### 常见问题：

1. **连接超时**: 检查模型服务器是否正常运行，网络连接是否正常
2. **认证失败**: 确认API密钥是否正确
3. **编码错误**: 确保系统支持UTF-8编码
4. **依赖缺失**: 运行 `pip install -r requirements.txt` 安装所有依赖

### 调试模式：

工具使用Python logging模块，可以通过修改日志级别获取更详细的信息：

```python
logging.basicConfig(level=logging.DEBUG)
```

## 许可证

MIT License 